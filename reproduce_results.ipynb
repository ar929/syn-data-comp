{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preamble/setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import cv2\n",
    "import random\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from fractions import Fraction\n",
    "\n",
    "import torch\n",
    "from torchvision.datasets import CIFAR10\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import TensorDataset, Subset, RandomSampler, DataLoader, ConcatDataset\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option for whether to only plot the results from saved scores, or to recalculate from scratch.\n",
    "# Note this is very slow, but allows reproduction of all results\n",
    "recalculate_results = False\n",
    "\n",
    "device_name = utils.get_device()\n",
    "device = torch.device(device_name)\n",
    "CNN_params_dict = utils.CNN_params_setup(device)\n",
    "dropout_conv, dropout_fc = CNN_params_dict['dropout_conv'], CNN_params_dict['dropout_fc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plotting parameters for uniformity\n",
    "my_fig_size = (7,6) # figure size\n",
    "ms = 10 # marker size\n",
    "lw = 4 # line width\n",
    "title_size = 18\n",
    "label_size = 14\n",
    "legend_size = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original data CNN learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# if recalculate_results: \n",
    "# Load the CIFAR-10 data to memory\n",
    "full_cifar_dataset = CIFAR10\n",
    "# Define data transformations\n",
    "transform = transforms.Compose([transforms.ToTensor(),]) # Convert PIL Image to PyTorch Tensor\n",
    "\n",
    "train_dataset = full_cifar_dataset(\n",
    "    root=f'./{\"data/cifar-10-orig\"}',  # Change the root directory as needed\n",
    "    train=True,      # Set to True for the training set\n",
    "    transform=transform,\n",
    "    download=True)\n",
    "\n",
    "test_dataset = full_cifar_dataset(\n",
    "    root=f'./{\"data/cifar-10-orig\"}',  # Change the root directory as needed\n",
    "    train=False,     # Set to False for the test set\n",
    "    transform=transform,\n",
    "    download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup our main n_orig = 1024 sample\n",
    "N = 1024\n",
    "\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "\n",
    "random_indices = random.sample(range(len(train_dataset)), N)\n",
    "train_samp = Subset(train_dataset, random_indices)\n",
    "# Separate the images and labels\n",
    "images_samp = torch.stack([train_samp[i][0] for i in range(N)])  # Stack the image tensors\n",
    "labels_samp = torch.tensor([train_samp[i][1] for i in range(N)])  # Convert labels to a tensor\n",
    "\n",
    "# Return as TensorDataset\n",
    "subset_train_dataset = TensorDataset(images_samp, labels_samp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline classification accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes about 1 min per repeat to run (on my gpu)\n",
    "if recalculate_results:\n",
    "    repeats = 25\n",
    "    baseline_scores_list = []\n",
    "    for i in range(repeats):\n",
    "        print(f\"Calculating baseline scores, repeat {i + 1} of {repeats}\")\n",
    "        baseline_model = utils.Cifar_CNN(num_channels = 3, classes = 10, dropout_conv = dropout_conv, dropout_fc = dropout_fc).to(device)\n",
    "\n",
    "        _, _, test_score = utils.nn_trainer(baseline_model, subset_train_dataset, test_dataset, opt_type = \"adam\", \n",
    "                CNN_params_dict = CNN_params_dict, loss_type = \"nll\", lr_sched = None, device_str = device_name, verbose = False)\n",
    "        \n",
    "        baseline_scores_list += [test_score]  \n",
    "        end_time = time.time()\n",
    "\n",
    "    avg_baseline_accuracy = np.mean(baseline_scores_list)\n",
    "    print(f\"Baseline classification accuracy: {avg_baseline_accuracy}\")\n",
    "else:\n",
    "    avg_baseline_accuracy = 0.42261 # score hard-coded from full run (easier than saving to a separate file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes about 6 hours to run on my gpu\n",
    "orig_lc_json_name = \"scores/orig_data_learning_curve.json\"\n",
    "\n",
    "if recalculate_results:\n",
    "    n_samp = [1000, 2000, 4000, 8000, 15000, 30000, 50000]\n",
    "    epoch_list = [20, 30, 50, 70, 100]\n",
    "    lc_orig_dict = {}\n",
    "\n",
    "    for j, e in enumerate(epoch_list):\n",
    "        lc_orig_dict[f\"Epochs = {e}\"] = {}\n",
    "        lc_CNN_params_dict = CNN_params_dict\n",
    "        lc_CNN_params_dict['epochs'] = e\n",
    "        for i in range(len(n_samp)):\n",
    "            start_time = time.time()\n",
    "\n",
    "            n = n_samp[i]\n",
    "            random_indices = random.sample(range(len(train_dataset)), n)\n",
    "            lc_train_samp = Subset(train_dataset, random_indices)\n",
    "            # Separate the images and labels\n",
    "            images = torch.stack([lc_train_samp[i][0] for i in range(n)])  # Stack the image tensors\n",
    "            labels = torch.tensor([lc_train_samp[i][1] for i in range(n)])  # Convert labels to a tensor\n",
    "\n",
    "            # Return as TensorDataset\n",
    "            lc_subset_train_dataset = TensorDataset(images, labels)\n",
    "\n",
    "            lc_model = utils.Cifar_CNN(num_channels = 3, classes = 10, dropout_conv = dropout_conv, dropout_fc = dropout_fc).to(device)\n",
    "\n",
    "            _, _, test_score = utils.nn_trainer(lc_model, lc_subset_train_dataset, test_dataset, opt_type = \"adam\", \n",
    "                    CNN_params_dict=lc_CNN_params_dict, loss_type = \"nll\", lr_sched = None, device_str = device_name, verbose = False)\n",
    "            \n",
    "            lc_orig_dict[f\"Epochs = {e}\"][n] = test_score  \n",
    "            end_time = time.time()\n",
    "            print(f\"Run {i + 1} out of {len(n_samp)} samples and {j+1} out of {len(epoch_list)} epochs, for {n} samples and {e} epochs. Test score = {round(test_score, 3)}. Runtime = {round(end_time - start_time, 1)} seconds\")\n",
    "            \n",
    "    with open(orig_lc_json_name, 'w') as json_file:\n",
    "        json.dump(lc_orig_dict, json_file)\n",
    "else:\n",
    "    with open(orig_lc_json_name, 'r') as json_file:\n",
    "            lc_orig_dict = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data for seaborn\n",
    "data_list = []\n",
    "for epochs, data in lc_orig_dict.items():\n",
    "    for amount, accuracy in data.items():\n",
    "        data_list.append({'Epochs': epochs, 'Amount': int(amount), 'Accuracy': accuracy})\n",
    "\n",
    "df = pd.DataFrame(data_list)\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=my_fig_size)\n",
    "sns.lineplot(data=df, x='Amount', y='Accuracy', hue='Epochs', marker='o', markersize = ms, linewidth = lw, palette='cividis_r')\n",
    "\n",
    "# Set log scale for x-axis\n",
    "plt.xscale('log')\n",
    "\n",
    "plt.xlabel(\"Amount of training data (Log scale)\", fontsize=label_size)\n",
    "plt.ylabel(\"Accuracy\", fontsize=label_size)\n",
    "plt.title(\"Learning curve for varying epochs\", fontsize=title_size)\n",
    "xticks = [1000, 10000, 50000]\n",
    "plt.xticks(xticks, labels=[str(x) for x in xticks])\n",
    "plt.legend(fontsize=legend_size)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conventional transformation image samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = cv2.imread('data/bird_example.png')\n",
    "test_img = cv2.cvtColor(test_img, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(test_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Standard\n",
    "nrow = 3\n",
    "ncol = 7\n",
    "fig, axes = plt.subplots(nrow, ncol, figsize=(15, 6))\n",
    "plt.subplots_adjust(hspace=-0.61, wspace=-0.4)\n",
    "for i in range(nrow):\n",
    "    for j in range(ncol):\n",
    "        ax = axes[i, j]\n",
    "        if j == 0:\n",
    "            ax.imshow(np.ones((32, 32, 3)))  # White image\n",
    "            if i == 1:\n",
    "                ax.imshow(test_img)\n",
    "            ax.axis('off')\n",
    "        elif j == 1:\n",
    "            ax.imshow(np.ones((32, 32, 3)))  # White image\n",
    "            if i == 1:\n",
    "                ax.annotate('', xy=(2, 16), xytext=(30, 16), arrowprops=dict(arrowstyle='<-', lw=2.5, color='lightseagreen'))\n",
    "            ax.axis('off')\n",
    "        elif j >= 2:\n",
    "            gamma = j - 1\n",
    "            img = utils.img_transformation(torch.tensor(test_img).T, prob = 1, gamma = gamma, seed = (53 + (i * j))).T\n",
    "            ax.imshow(img)\n",
    "            if i == 0:\n",
    "                ax.set_title(f\"γ = {gamma}\", fontsize=28) \n",
    "            ax.axis('off')\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conventional transformation optimisation\n",
    "### Accuracy vs intensity gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_conv_gamma_json_name = \"scores/acc_vs_conv_gamma.json\"\n",
    "\n",
    "if recalculate_results:\n",
    "    gamma_list = [0, 0.5, 1, 1.5, 2, 2.5, 3, 4, 5]\n",
    "    alpha_list = [1.01, 1.5, 2.5, 4, 6, 10]\n",
    "\n",
    "    test_accs_per_alpha_dict = {}\n",
    "    repeats = 5\n",
    "    real_accs_per_aug_ratio = {}\n",
    "    for ind, alpha in enumerate(alpha_list):\n",
    "        test_acc_repeats = []\n",
    "        for i in range(repeats):\n",
    "            start_time = time.time()\n",
    "            i_test_acc_list = []\n",
    "\n",
    "            for gamma in gamma_list:    \n",
    "                cnn_model = utils.Cifar_CNN(num_channels = 3, classes = 10, dropout_conv = dropout_conv, dropout_fc = dropout_fc).to(device)\n",
    "                _, _, test_score = utils.nn_trainer(cnn_model, subset_train_dataset, test_dataset, opt_type = \"adam\", CNN_params_dict=CNN_params_dict, \n",
    "                                                    loss_type = \"nll\", lr_sched = None, device_str = device_name, verbose = False, \n",
    "                                                    augmentation = True, aug_ratio = alpha, aug_var = gamma)\n",
    "                i_test_acc_list += [test_score]\n",
    "            test_acc_repeats += [i_test_acc_list]\n",
    "            end_time = time.time()\n",
    "            print(f\"Run for alpha number {ind+1} out of {len(alpha_list)} ({alpha}) and repeat {i+1} of {repeats} complete (note each run tests {len(gamma_list)} gamma options). Runtime = {round(end_time - start_time, 1)} seconds\")\n",
    "\n",
    "        test_accs_per_alpha_dict[alpha] = test_acc_repeats\n",
    "            \n",
    "    with open(acc_conv_gamma_json_name, 'w') as json_file:\n",
    "        json.dump(test_accs_per_alpha_dict, json_file)\n",
    "else:\n",
    "    with open(acc_conv_gamma_json_name, 'r') as json_file:\n",
    "            test_accs_per_alpha_dict = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_axis = [-1] + var_list\n",
    "alpha_list = list(test_accs_per_alpha_dict.keys())\n",
    "gamma_list = [0, 0.5, 1, 1.5, 2, 2.5, 3, 4, 5]\n",
    "\n",
    "# Prepare the data for seaborn\n",
    "data_list = []\n",
    "for alpha in alpha_list:\n",
    "    this_accs = np.array(test_accs_per_alpha_dict[alpha])\n",
    "    lq, med, uq = np.percentile(this_accs / avg_baseline_accuracy, [25, 50, 75], axis=0)\n",
    "    lqd, uqd = med - lq, uq - med\n",
    "\n",
    "    data_list.append({\n",
    "        'Augmentation Ratio': alpha,\n",
    "        'x': gamma_list,\n",
    "        'Median Accuracy': med,\n",
    "        'Lower Deviation': lqd,\n",
    "        'Upper Deviation': uqd\n",
    "    })\n",
    "\n",
    "# Convert to DataFrame for easier plotting\n",
    "df = pd.DataFrame(data_list)\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=my_fig_size)\n",
    "palette = sns.color_palette('flare', len(alpha_list)+2)\n",
    "\n",
    "# Plot each augmentation ratio\n",
    "for i, alpha in enumerate(alpha_list):\n",
    "    plt.errorbar(df.loc[i, 'x'], df.loc[i, 'Median Accuracy'], \n",
    "                 yerr=[df.loc[i, 'Lower Deviation'], df.loc[i, 'Upper Deviation']], \n",
    "                 fmt='o-', label=f\"α = {alpha}\", capsize=5, color=palette[i], \n",
    "                 markersize = ms, linewidth = lw)\n",
    "\n",
    "# Aesthetics\n",
    "plt.title(\"Relative Accuracy vs γ\", fontsize=title_size)\n",
    "plt.ylim(0.9, 1.3)\n",
    "plt.legend(fontsize=legend_size)\n",
    "plt.xlabel(\"Intensity Parameter, γ\", fontsize=label_size)\n",
    "plt.ylabel(\"Relative Accuracy\", fontsize=label_size)\n",
    "plt.axhline(y=1, color='gray', linestyle='--', lw = 2.5)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 2.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy vs ratio alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 2.5\n",
    "alphas = [1.5, 2.5, 5, 7, 10, 13, 16, 20, 25, 30, 35, 40, 50]\n",
    "acc_conv_alpha_json_name = \"scores/acc_vs_conv_alpha.json\"\n",
    "\n",
    "if recalculate_results:\n",
    "    acc_aug_dict = {}\n",
    "    N = 5\n",
    "    for j in range(N):\n",
    "        t0 = time.time()\n",
    "        acc_per_rep_list = []\n",
    "        for i, alpha in enumerate(alphas):\n",
    "            print(f\"Calculating scores for rep {j+1} of {N}, and alpha {i+1} of {len(alphas)}\")\n",
    "            ti = time.time()\n",
    "            print(f\"Calculating for alpha {i+1} out of {len(alphas)} ({alpha}), repeat {j+1} of {N}. Time so far = {round((ti-t0)/60, 1)} minutes.\")\n",
    "            cnn_mod = utils.Cifar_CNN(num_channels = 3, classes = 10, dropout_conv = dropout_conv, dropout_fc = dropout_fc).to(device)\n",
    "            _, _, test_acc = utils.nn_trainer(cnn_model, subset_train_dataset, test_dataset, opt_type = \"adam\", CNN_params_dict=CNN_params_dict, \n",
    "                                                    loss_type = \"nll\", lr_sched = None, device_str = device_name, verbose = False, \n",
    "                                                    augmentation = True, aug_ratio = alpha, aug_var = gamma)\n",
    "            acc_per_rep_list += [test_acc]\n",
    "        acc_aug_dict[j] = acc_per_rep_list\n",
    "\n",
    "\n",
    "    # Save the output dictionary to json file\n",
    "    with open(acc_conv_alpha_json_name, 'w') as json_file:\n",
    "        json.dump(acc_aug_dict, json_file)\n",
    "else:\n",
    "    with open(acc_conv_alpha_json_name, 'r') as json_file:\n",
    "            acc_aug_dict = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = [1.5, 2.5, 5, 7, 10, 13, 16, 20, 25, 30, 35, 40, 50]\n",
    "alpha_arr = np.array(list(acc_aug_dict.values()))\n",
    "lq, med, uq = np.percentile(alpha_arr / avg_baseline_accuracy, [25, 50, 75], axis=0)\n",
    "lqd, uqd = med - lq, uq - med\n",
    "\n",
    "plt.figure(figsize=my_fig_size)\n",
    "\n",
    "plt.errorbar(alphas, med, yerr=[lqd, uqd], fmt='o-', capsize=5, \n",
    "            markersize = ms, linewidth = lw,)\n",
    "            # markeredgecolor='white', markeredgewidth=0.5, )\n",
    "\n",
    "plt.ylabel(\"Relative Accuracy\", fontsize=12)\n",
    "plt.xlabel(\"Augmentation Ratio, $α_c$\", fontsize=12)\n",
    "plt.title(\"Relative Accuracy vs $α_c$\", fontsize=16)\n",
    "# plt.annotate(f\"Error bars showing median & IQR across {len(acc_aug_dict)} tests\", \n",
    "#              xy=(0.5, 0.97), xycoords='axes fraction', \n",
    "#              fontsize=10, ha='center', va='center')\n",
    "# plt.grid(True)  # Add grid for better readability\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning curve on full data with augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 2.5\n",
    "alphas = [None, 2, 5, 20, 50]\n",
    "n_samp = [100, 200, 500, 1024, 2000, 4000, 8000, 15000, 30000, 50000]\n",
    "\n",
    "aug_lc_dict_json_name = \"scores/aug_acc_lc.json\"\n",
    "\n",
    "if recalculate_results:\n",
    "    train_length = len(train_dataset)\n",
    "    seed = 42\n",
    "    random.seed(seed)\n",
    "    aug_lc_dict = {}\n",
    "    # Loop through the alphas (amount of augmented data to use)\n",
    "    for j, alpha in enumerate(alphas):\n",
    "        # Set up name and aug_lc_dict for this iteration depending on augmentation type\n",
    "        aug_bool = alpha is not None\n",
    "        if aug_bool:\n",
    "            score_name = f\"alpha = {alpha}\"\n",
    "        else:\n",
    "            score_name = \"No augmentation\"\n",
    "        aug_lc_dict[score_name] = {}\n",
    "\n",
    "        # Loop through the data sample lengths\n",
    "        for i, n in enumerate(n_samp):\n",
    "            # Time the code\n",
    "            start_time = time.time()\n",
    "            \n",
    "            # Sample the cifar data n times (n being the current number of samples for this iteration) without replacement\n",
    "            random_indices = random.sample(range(train_length), n)\n",
    "            # Organise into a dataset\n",
    "            random_reals = [train_dataset[i] for i in random_indices]\n",
    "            random_x, random_y = zip(*random_reals)  # Unzip data into separate lists\n",
    "            lc_subset_train_dataset = TensorDataset(torch.stack(random_x), torch.tensor(random_y))\n",
    "            \n",
    "            cnn_mod = utils.Cifar_CNN(num_channels = 3, classes = 10, dropout_conv = dropout_conv, dropout_fc = dropout_fc).to(device)\n",
    "            _, _, test_acc = utils.nn_trainer(cnn_mod, lc_subset_train_dataset, test_dataset, opt_type = \"adam\", CNN_params_dict=CNN_params_dict, \n",
    "                                                        loss_type = \"nll\", lr_sched = None, device_str = device_name, verbose = False, \n",
    "                                                        augmentation = aug_bool, aug_ratio = alpha, aug_var = gamma)\n",
    "            aug_lc_dict[score_name][n] = test_acc  \n",
    "            end_time = time.time()\n",
    "            print(f\"Run {(i+1) + (j)*(len(n_samp))} out of {len(n_samp) * len(alphas)} complete, for {n} samples and {score_name}. Test score = {round(test_acc, 3)}. Runtime = {round(end_time - start_time, 1)} seconds\")\n",
    "\n",
    "    # Save the output dictionary to json file\n",
    "    with open(aug_lc_dict_json_name, 'w') as json_file:\n",
    "        json.dump(aug_lc_dict, json_file)\n",
    "else:\n",
    "    with open(aug_lc_dict_json_name, 'r') as json_file:\n",
    "        aug_lc_dict = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yo need to turn from dict into df\n",
    "# Load the CSV data\n",
    "# lc_df = lc_df_raw.set_index(\"n_real\")\n",
    "# lc_df.loc[50000, \"α = 50\"] = 0.8789137086050223\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=my_fig_size)\n",
    "\n",
    "num_columns = len(lc_df.columns)\n",
    "palette = sns.color_palette('magma_r', num_columns+4)\n",
    "\n",
    "# Plot each column with a distinct color\n",
    "for i, column in enumerate(lc_df.columns):\n",
    "    # legend_entry = column.replace('α', '$α_c$')\n",
    "    plt.semilogx(lc_df.index, lc_df[column], label=column, \n",
    "                 marker='o', color=palette[i+2], markersize=10, \n",
    "                 linewidth=4, markeredgecolor='white', markeredgewidth=0.5)\n",
    "\n",
    "# Aesthetics\n",
    "plt.xlabel(\"Amount of original data (Log scale)\", fontsize=12)\n",
    "plt.ylabel(\"Accuracy\", fontsize=12)\n",
    "plt.title(\"Learning curve for different augmentation ratios\", fontsize=14)\n",
    "plt.legend(fontsize=10.5)\n",
    "xticks = [100, 1000, 10000, 50000]\n",
    "plt.xticks(xticks, labels=[str(x) for x in xticks])\n",
    "plt.ylim(0, 1.05)  # Set Y limits if needed\n",
    "plt.grid(True)  # Add grid for better readability\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ImageGPT output samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_sizes = [3]\n",
    "prompt_sizes = {\"small\":0.25, \"med\":0.5, \"large\":0.75}\n",
    "feature_extractor, model, clusters, device = utils.igpt_model_setup(device_name=\"cpu\")\n",
    "\n",
    "real_img = train_dataset[2993][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 10\n",
    "\n",
    "all_syn_imgs = utils.create_igpt_img(real_img, 32, feature_extractor, clusters, model, device, rep_sizes, prompt_sizes, return_img_dict = True, gen_seed = seed)\n",
    "# Calculate the number of rows and columns\n",
    "num_rows = len(all_syn_imgs)\n",
    "num_cols = 5\n",
    "fig, axes = plt.subplots(nrows=num_rows, ncols=num_cols, figsize=(20, 3*num_rows))\n",
    "plt.subplots_adjust(hspace=0.2, wspace=-0.7)\n",
    "\n",
    "for i, (syn_set, item) in enumerate(all_syn_imgs.items()):\n",
    "    for j in range(num_cols):\n",
    "        ax = axes[i, j]\n",
    "        if j == 0:\n",
    "            if \"small\" in syn_set:\n",
    "                frac = 0.25\n",
    "            elif \"med\" in syn_set:\n",
    "                frac = 0.5\n",
    "            elif \"large\" in syn_set:\n",
    "                frac = 0.75\n",
    "\n",
    "            # Generate the white pixels\n",
    "            white_pixels = torch.ones_like(real_img[:, :int((1 - frac) * 32), :])\n",
    "            # Concatenate white pixels to the bottom of the original image\n",
    "            extended_img = torch.cat([real_img[:, :int(frac * 32), :], white_pixels], dim=1)\n",
    "            # Plot the extended image in the first column\n",
    "            ax.imshow(extended_img.permute(1, 2, 0), aspect='equal')\n",
    "            ax.axis('off')\n",
    "            frac_str = fr\"$\\frac{{{Fraction(frac).limit_denominator().numerator}}}{{{Fraction(frac).limit_denominator().denominator}}}$\"\n",
    "            ax.text(-0.75, 0.5, f\"β = {frac_str}\", transform=ax.transAxes, rotation='horizontal',\n",
    "                    verticalalignment='center', horizontalalignment='right', fontsize=36, color='black')\n",
    "            # ax.text(-0.18, 0.5, \"prompt\", transform=ax.transAxes, rotation='horizontal',\n",
    "            #         verticalalignment='center', horizontalalignment='right', fontsize=20, color='black')\n",
    "        # Plot the white image with an arrow in the second column\n",
    "        elif j == 1:\n",
    "            ax.imshow(np.ones((32, 32, 3)))  # White image\n",
    "            ax.annotate('', xy=(2, 16), xytext=(30, 16), arrowprops=dict(arrowstyle='<-', lw=2.5, color='lightseagreen'))\n",
    "            ax.axis('off')\n",
    "        # Plot the three images from the item list in columns 3, 4, and 5\n",
    "        else:\n",
    "            ax.imshow(item[j - 2].transpose(1, 2, 0))\n",
    "            ax.axis('off')\n",
    "# Show the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAN output samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the GANs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### need to do these GANs 1, 3, 6, 7\n",
    "# parent_path = \"data/paper_cifar_gan_aug_ratio_15.6/\"\n",
    "# parent_path = \"data/paper_cifar_gan_aug_ratio_18.0_aug_var_1.8/\"\n",
    "# parent_path = \"data/paper_cifar_gan_aug_ratio_10.0_aug_var_1/\"\n",
    "# parent_path = \"data/paper_cifar_gan_aug_ratio_10.0_aug_var_0/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GAN option 1\n",
    "# From Bayesian optimisation:\n",
    "if recalculate_results:\n",
    "    opt_gan_params = {\n",
    "        'dropout_conv': 0.407,\n",
    "        'gan_epochs': 791,\n",
    "        'p_drop_disc': 0.453,\n",
    "        'lr_gen': 2.64e-05,\n",
    "        'lr_disc': 2.42e-05,\n",
    "        'gan_aug_ratio': 15.6,\n",
    "        'gan_aug_var': 0.0,\n",
    "        'device_name': 'cuda',\n",
    "        'save_name' : \"models/gan_1\"}\n",
    "\n",
    "    other_params = {'device_name' : \"mps\", 'beta_1' : 0.5, 'beta_2' : 0.999999, 'gan_wd' : 0.0015, 'input_size' : 150,\n",
    "                        'n_layers_gen' : 5, 'n_layers_disc' : 5, 'label_smoothing' : 0, 'disc_noise_std' : 0, \n",
    "                        'gan_val_split' : 0, 'gan_batch_size' : 64, 'loader_num_workers' : 0, 'test_reps' : 5}\n",
    "\n",
    "    !python train_cifar_gan.py --dataset_name cifar10 --out_path {opt_gan_params['save_name']}      --save_type final  --samples 1024 --split_before_samp False      --epochs {opt_gan_params['gan_epochs']} \\\n",
    "        --lr_gen {opt_gan_params['lr_gen']}           --lr_disc {opt_gan_params['lr_disc']}         --beta_1 {other_params['beta_1']}             --beta_2 {other_params['beta_2']} \\\n",
    "        --wd {other_params['gan_wd']}                 --input_size {other_params['input_size']}     --n_layers_gen {other_params['n_layers_gen']} --n_layers_disc {other_params['n_layers_disc']} \\\n",
    "        --p_drop {opt_gan_params['p_drop_disc']}      --device_name {other_params['device_name']}   --augmentation True                           --num_workers {other_params['loader_num_workers']} \\\n",
    "        --aug_ratio {opt_gan_params['gan_aug_ratio']} --aug_var {opt_gan_params['gan_aug_var']}     --training_verbosity 0.5 \\\n",
    "        --test_methods class_rel_acc,fid,fid_inf      --test_reps {other_params['test_reps']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GAN option 2\n",
    "# From Bayesian optimisation:\n",
    "if recalculate_results:\n",
    "    opt_gan_params = {\n",
    "        'dropout_conv': 0.68,\n",
    "        'gan_epochs': 500,\n",
    "        'p_drop_disc': 0.4,\n",
    "        'lr_gen': 3e-5,\n",
    "        'lr_disc': 3e-4,\n",
    "        'gan_aug_ratio': 18,\n",
    "        'gan_aug_var': 1.8, ####0\n",
    "        'device_name': 'cuda',\n",
    "        'save_name' : \"models/gan_2\"}\n",
    "\n",
    "    other_params = {'device_name' : \"mps\", 'beta_1' : 0.5, 'beta_2' : 0.999999, 'gan_wd' : 0.0015, 'input_size' : 150,\n",
    "                        'n_layers_gen' : 5, 'n_layers_disc' : 5, 'label_smoothing' : 0, 'disc_noise_std' : 0, \n",
    "                        'gan_val_split' : 0, 'gan_batch_size' : 64, 'loader_num_workers' : 0, 'test_reps' : 5}\n",
    "\n",
    "    !python train_cifar_gan.py --dataset_name cifar10 --out_path {opt_gan_params['save_name']}      --save_type final  --samples 1024 --split_before_samp False      --epochs {opt_gan_params['gan_epochs']} \\\n",
    "        --lr_gen {opt_gan_params['lr_gen']}           --lr_disc {opt_gan_params['lr_disc']}         --beta_1 {other_params['beta_1']}             --beta_2 {other_params['beta_2']} \\\n",
    "        --wd {other_params['gan_wd']}                 --input_size {other_params['input_size']}     --n_layers_gen {other_params['n_layers_gen']} --n_layers_disc {other_params['n_layers_disc']} \\\n",
    "        --p_drop {opt_gan_params['p_drop_disc']}      --device_name {other_params['device_name']}   --augmentation True                           --num_workers {other_params['loader_num_workers']} \\\n",
    "        --aug_ratio {opt_gan_params['gan_aug_ratio']} --aug_var {opt_gan_params['gan_aug_var']}     --training_verbosity 0.5 \\\n",
    "        --test_methods class_rel_acc,fid,fid_inf      --test_reps {other_params['test_reps']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GAN Option 3\n",
    "# From manual search\n",
    "if recalculate_results:\n",
    "    opt_gan_params = {\n",
    "        'dropout_conv': 0.25,\n",
    "        'gan_epochs': 400,\n",
    "        'p_drop_disc': 0.25,\n",
    "        'lr_gen': 0.00005,\n",
    "        'lr_disc': 0.00005,\n",
    "        'gan_aug_ratio': 10,\n",
    "        'gan_aug_var': 1,\n",
    "        'device_name': 'cuda',\n",
    "        'save_name' : \"models/gan_3\"}\n",
    "\n",
    "    other_params = {'device_name' : \"mps\", 'beta_1' : 0.5, 'beta_2' : 0.999999, 'gan_wd' : 0.0015, 'input_size' : 150,\n",
    "                        'n_layers_gen' : 5, 'n_layers_disc' : 5, 'label_smoothing' : 0, 'disc_noise_std' : 0, \n",
    "                        'gan_val_split' : 0, 'gan_batch_size' : 64, 'loader_num_workers' : 0, 'test_reps' : 5}\n",
    "\n",
    "    !python train_cifar_gan.py --dataset_name cifar10 --out_path {opt_gan_params['save_name']}      --save_type final  --samples 1024 --split_before_samp False      --epochs {opt_gan_params['gan_epochs']} \\\n",
    "        --lr_gen {opt_gan_params['lr_gen']}           --lr_disc {opt_gan_params['lr_disc']}         --beta_1 {other_params['beta_1']}             --beta_2 {other_params['beta_2']} \\\n",
    "        --wd {other_params['gan_wd']}                 --input_size {other_params['input_size']}     --n_layers_gen {other_params['n_layers_gen']} --n_layers_disc {other_params['n_layers_disc']} \\\n",
    "        --p_drop {opt_gan_params['p_drop_disc']}      --device_name {other_params['device_name']}   --augmentation True                           --num_workers {other_params['loader_num_workers']} \\\n",
    "        --aug_ratio {opt_gan_params['gan_aug_ratio']} --aug_var {opt_gan_params['gan_aug_var']}     --training_verbosity 0.5 \\\n",
    "        --test_methods class_rel_acc,fid,fid_inf      --test_reps {other_params['test_reps']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GAN Option 4\n",
    "# From manual search\n",
    "if recalculate_results:\n",
    "    opt_gan_params = {\n",
    "        'dropout_conv': 0.25,\n",
    "        'gan_epochs': 400,\n",
    "        'p_drop_disc': 0.25,\n",
    "        'lr_gen': 0.00005,\n",
    "        'lr_disc': 0.00005,\n",
    "        'gan_aug_ratio': 10,\n",
    "        'gan_aug_var': 0,\n",
    "        'device_name': 'cuda',\n",
    "        'save_name' : \"models/gan_4\"}\n",
    "\n",
    "    other_params = {'device_name' : \"mps\", 'beta_1' : 0.5, 'beta_2' : 0.999999, 'gan_wd' : 0.0015, 'input_size' : 150,\n",
    "                        'n_layers_gen' : 5, 'n_layers_disc' : 5, 'label_smoothing' : 0, 'disc_noise_std' : 0, \n",
    "                        'gan_val_split' : 0, 'gan_batch_size' : 64, 'loader_num_workers' : 0, 'test_reps' : 5}\n",
    "\n",
    "    !python train_cifar_gan.py --dataset_name cifar10 --out_path {opt_gan_params['save_name']}      --save_type final  --samples 1024 --split_before_samp False      --epochs {opt_gan_params['gan_epochs']} \\\n",
    "        --lr_gen {opt_gan_params['lr_gen']}           --lr_disc {opt_gan_params['lr_disc']}         --beta_1 {other_params['beta_1']}             --beta_2 {other_params['beta_2']} \\\n",
    "        --wd {other_params['gan_wd']}                 --input_size {other_params['input_size']}     --n_layers_gen {other_params['n_layers_gen']} --n_layers_disc {other_params['n_layers_disc']} \\\n",
    "        --p_drop {opt_gan_params['p_drop_disc']}      --device_name {other_params['device_name']}   --augmentation True                           --num_workers {other_params['loader_num_workers']} \\\n",
    "        --aug_ratio {opt_gan_params['gan_aug_ratio']} --aug_var {opt_gan_params['gan_aug_var']}     --training_verbosity 0.5 \\\n",
    "        --test_methods class_rel_acc,fid,fid_inf      --test_reps {other_params['test_reps']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 10\n",
    "cifar10_classes = np.arange(n_classes)\n",
    "model_version = \"final\"\n",
    "\n",
    "label_dict = {0: b'airplane', 1: b'automobile', 2: b'bird', 3: b'cat', 4: b'deer', 5: b'dog', 6: b'frog', 7: b'horse', 8: b'ship', 9: b'truck'} # Output from CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path_list = ['models/gan_1', 'models/gan_2', 'models/gan_3', 'models/gan_4']\n",
    "\n",
    "if not recalculate_results: # just to tidy up some parameters for the plotting\n",
    "        other_params = {'input_size' : 150, 'n_layers_gen' : 5}\n",
    "\n",
    "gen_models = {}\n",
    "for i, model_path in enumerate(model_path_list):\n",
    "    gen_model = {}\n",
    "    for label in cifar10_classes:\n",
    "        ### Need to do this preamble for the load_model function\n",
    "        #net_generator = gan_utils.Generator().apply(gan_utils.weights_init)\n",
    "        #optimizer_generator = optim.Adam(net_generator.parameters(), lr=2e-4, betas=(.5, .999))\n",
    "        #net_generator, optimizer_generator, epoch = gan_utils.load_model(path_to_model, net_generator, optimizer_generator)\n",
    "        path_to_model = f\"{model_path}/label_{label}/model/dcgan_generator_{model_version}.pth\"\n",
    "        gen_model[label] = torch.load(path_to_model, map_location=device)\n",
    "\n",
    "    print(model_path)\n",
    "    utils.plot_gan_output(gen_model, n_syn = 1, label_dict=label_dict, nn_input_size=other_params['input_size'], \n",
    "                                nn_n_layers_gen=other_params['n_layers_gen'], model_type=\"v2\", n_classes=n_classes, seed = 42, man_title = f\"Opt. {i+1}\")\n",
    "\n",
    "\n",
    "    test_scores_json_path = f\"{model_path}/test_scores.json\"\n",
    "    scores_summary_dict = json.load(open(test_scores_json_path, 'r'))\n",
    "\n",
    "    this_score = (scores_summary_dict[\"mean\"] if \"mean\" in scores_summary_dict.keys() else scores_summary_dict)\n",
    "    display(this_score)\n",
    "\n",
    "    gen_models[i+1] = gen_model\n",
    "\n",
    "    # full_scores_set[model_path] = this_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the output samples of two top models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot_gan_output(gen_models[2], n_syn = 1, label_dict=label_dict, nn_input_size=other_params['input_size'], nn_n_layers_gen=other_params['n_layers_gen'], \n",
    "    model_type=\"v2\", n_classes=n_classes, seed = 42, man_title = \"Sample Output from GAN Model 2\", wrap_single = True)\n",
    "\n",
    "utils.plot_gan_output(gen_models[4], n_syn = 1, label_dict=label_dict, nn_input_size=other_params['input_size'], nn_n_layers_gen=other_params['n_layers_gen'], \n",
    "    model_type=\"v2\", n_classes=n_classes, seed = 42, man_title = \"Sample Output from GAN Model 4\", wrap_single = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy vs FID\n",
    "### Conventional SD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress :: Calculating scores for aug var 1 of 6 and ratio 1 of 4 and rep 1 of 5.\n",
      "Progress :: Calculating classifier accuracy\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 4, got 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 36\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m#ti = time.time(); print(f\"Time since last update = {round((ti-t0)/60, 1)} minutes.\"); t0 = time.time()\u001b[39;00m\n\u001b[1;32m     35\u001b[0m cnn_v2_mod \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mCifar_CNN(num_channels \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m, classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m, dropout_conv \u001b[38;5;241m=\u001b[39m dropout_conv, dropout_fc \u001b[38;5;241m=\u001b[39m dropout_fc)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 36\u001b[0m _, _, real_acc, _ \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mnn_trainer(cnn_v2_mod, aug_train_data, test_dataset, device_str \u001b[38;5;241m=\u001b[39m device_name, verbose \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, \n\u001b[1;32m     37\u001b[0m                             CNN_params_dict\u001b[38;5;241m=\u001b[39mCNN_params_dict, augmentation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProgress :: Calculating FID_inf\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m#ti = time.time(); print(f\"Time since last update = {round((ti-t0)/60, 1)} minutes.\"); t0 = time.time()\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 4, got 3)"
     ]
    }
   ],
   "source": [
    "reps = 5\n",
    "gammas = [1, 2, 2.5, 3, 4, 5]\n",
    "alphas = [3, 5, 7, 9]\n",
    "\n",
    "all_acc_inds_per_rep = {}\n",
    "all_fid_infs_per_rep = {}\n",
    "for rep in range(reps):\n",
    "    t00 = time.time()\n",
    "    accs_per_var = {}\n",
    "    fids_per_var = {}\n",
    "    for j, gamma in enumerate(gammas):\n",
    "        acc_per_aug = []\n",
    "        acc_ind_per_aug = []\n",
    "        fid_inf_per_aug = []\n",
    "        for i, alpha in enumerate(alphas):\n",
    "\n",
    "            t0 = time.time()\n",
    "            print(f\"Progress :: Calculating scores for aug var {j+1} of {len(gammas)} and ratio {i+1} of {len(alphas)} and rep {rep+1} of {reps}.\")\n",
    "            # I want to manually do my augmenting, so I can use the same set for the classifier-augmenting, and for the FID calculation\n",
    "            real_size = len(subset_train_dataset)\n",
    "            aug_size = int(np.floor(real_size * alpha - real_size))\n",
    "            random_sampler = RandomSampler(subset_train_dataset, replacement=False, num_samples=aug_size)\n",
    "            aug_dataloader = DataLoader(subset_train_dataset, batch_size=1, sampler=random_sampler)\n",
    "            aug_imgs = []\n",
    "            aug_labels = []\n",
    "            for img, label in aug_dataloader:\n",
    "                new_img = utils.img_transformation(img, prob = 1, gamma = gamma)\n",
    "                aug_imgs += [new_img.squeeze(0)]; aug_labels += [label]\n",
    "            aug_data = TensorDataset(torch.stack(aug_imgs), torch.tensor(aug_labels))\n",
    "            aug_train_data = ConcatDataset([subset_train_dataset, aug_data])\n",
    "\n",
    "            print(f\"Progress :: Calculating classifier accuracy\")\n",
    "            #ti = time.time(); print(f\"Time since last update = {round((ti-t0)/60, 1)} minutes.\"); t0 = time.time()\n",
    "\n",
    "            cnn_v2_mod = utils.Cifar_CNN(num_channels = 3, classes = 10, dropout_conv = dropout_conv, dropout_fc = dropout_fc).to(device)\n",
    "            _, _, real_acc = utils.nn_trainer(cnn_v2_mod, aug_train_data, test_dataset, device_str = device_name, verbose = False, \n",
    "                                        CNN_params_dict=CNN_params_dict, augmentation = False)\n",
    "            \n",
    "            print(f\"Progress :: Calculating FID_inf\")\n",
    "            #ti = time.time(); print(f\"Time since last update = {round((ti-t0)/60, 1)} minutes.\"); t0 = time.time()\n",
    "\n",
    "            fid_inf_score = utils.calculate_FID_infinity_array(images_samp, torch.stack(aug_imgs), min_fake = 500, device_name = \"mps\")\n",
    "\n",
    "            acc_per_aug += [real_acc]\n",
    "            acc_ind_per_aug += [real_acc/avg_baseline_accuracy]\n",
    "            fid_inf_per_aug += [fid_inf_score]\n",
    "            t1 = time.time()\n",
    "            print(f\"    That took {(t1-t0)/60:.1f} minutes\")\n",
    "            \n",
    "        accs_per_var[gamma] = acc_ind_per_aug\n",
    "        fids_per_var[gamma] = fid_inf_per_aug\n",
    "    all_acc_inds_per_rep[rep] = accs_per_var\n",
    "    all_fid_infs_per_rep[rep] = fids_per_var\n",
    "    t11 = time.time()\n",
    "    print(f\"That rep took {(t11-t00)/60:.1f} minutes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort dis!\n",
    "\n",
    "save_scores = False\n",
    "if save_scores:\n",
    "    json.dump(all_acc_inds_per_rep, open(\"saved/scores/fid_vs_traug_multirun_accs.json\", \"w\"))\n",
    "    json.dump(all_fid_infs_per_rep, open(\"saved/scores/fid_vs_traug_multirun_fids.json\", \"w\"))\n",
    "\n",
    "load_scores = True\n",
    "if load_scores:\n",
    "    all_acc_inds_per_rep = json.load(open(\"saved/scores/fid_vs_traug_multirun_accs.json\", \"r\"))\n",
    "    all_fid_infs_per_rep = json.load(open(\"saved/scores/fid_vs_traug_multirun_fids.json\", \"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_vars = [1, 2, 2.5, 3, 4, 5]\n",
    "aug_ratios = [3, 5, 7, 9]\n",
    "\n",
    "load_scores = True\n",
    "if load_scores:\n",
    "    all_acc_inds_per_rep = json.load(open(\"saved/scores/fid_vs_traug_multirun_accs.json\", \"r\"))\n",
    "    all_fid_infs_per_rep = json.load(open(\"saved/scores/fid_vs_traug_multirun_fids.json\", \"r\"))\n",
    "\n",
    "# Function to calculate median for each key in a nested dictionary\n",
    "def calculate_median(data):\n",
    "    # Firstly reshape data so that the fields we want to aggregate across are on the inside of the dict\n",
    "    try:\n",
    "        reshaped_data = {key: {} for key in data[0].keys()}\n",
    "    except KeyError:\n",
    "        reshaped_data = {key: {} for key in data[\"0\"].keys()}\n",
    "    for outer_key, inner_dict in data.items():\n",
    "        for inner_key, values in inner_dict.items():\n",
    "            reshaped_data[inner_key][outer_key] = values\n",
    "    # Then calculate the medians on the inner dicts\n",
    "    median_dict = {key: None for key in reshaped_data.keys()}\n",
    "    for aug_var, inner_dict in reshaped_data.items():\n",
    "        median_dict[aug_var] = list(np.median(np.array(list(inner_dict.values())).T, axis=1))\n",
    "    return median_dict\n",
    "\n",
    "# Calculate medians for all_acc_inds_per_rep and all_fid_infs_per_rep dataframes\n",
    "median_accs = calculate_median(all_acc_inds_per_rep)\n",
    "median_fids = calculate_median(all_fid_infs_per_rep)\n",
    "\n",
    "full_med_fids = []\n",
    "full_med_accs = []\n",
    "full_med_ratios = []\n",
    "full_med_vars = []\n",
    "for i, (aug_var, fids) in enumerate(median_fids.items()):\n",
    "    full_med_fids += fids\n",
    "    full_med_accs += median_accs[aug_var]\n",
    "    full_med_ratios += aug_ratios\n",
    "    full_med_vars += [aug_vars[i]]*len(fids)\n",
    "med_plot_df = pd.DataFrame({\"fids\": full_med_fids, \"accs\": full_med_accs, \"aug_ratio\": full_med_ratios, \"aug_var\": full_med_vars})\n",
    "\n",
    "med_plot_df = med_plot_df.rename(columns={\"aug_var\":\"aug_intns\"})\n",
    "med_plot_df = med_plot_df.rename(columns={\"aug_ratio\":\"α\", \"aug_intns\":\"γ\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure with two subplots side by side\n",
    "ylim = [0.9, 1.2]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))  # 1 row, 2 columns\n",
    "\n",
    "# Plot 1: Constant Alpha (varying Gamma)\n",
    "sns.lineplot(ax=axes[0], data=med_plot_df, x='fids', y='accs', hue='α', marker='o', markersize = 12, linewidth = 5, palette=sns.color_palette(\"flare\", n_colors=4))\n",
    "axes[0].set_title('Lines are constant α as γ varies', fontsize = 20)\n",
    "axes[0].set_xlabel('i', fontsize = 20)\n",
    "axes[0].set_ylabel('Relative Accuracy', fontsize = 18)\n",
    "axes[0].legend(title='α')\n",
    "axes[0].grid(True, which='both', linestyle='--', color='gray', alpha=0.5)  # Faint and dashed grid\n",
    "axes[0].axhline(y=1, color='gray', linestyle='--', lw = 2.5)\n",
    "axes[0].set_ylim(ylim)\n",
    "\n",
    "# Plot 2: Constant Gamma (varying Alpha)\n",
    "sns.lineplot(ax=axes[1], data=med_plot_df, x='fids', y='accs', hue='γ', marker='o', markersize = 12, linewidth = 5, palette=sns.color_palette(\"crest\"))\n",
    "axes[1].set_title('Lines are constant γ as α varies', fontsize = 20)\n",
    "axes[1].set_xlabel('ii', fontsize = 20)\n",
    "axes[1].set_ylabel('', fontsize = 18)\n",
    "axes[1].legend(title='γ')\n",
    "axes[1].grid(True, which='both', linestyle='--', color='gray', alpha=0.5)  # Faint and dashed grid\n",
    "axes[1].axhline(y=1, color='gray', linestyle='--', lw = 2.5)\n",
    "axes[1].set_ylim(ylim)\n",
    "\n",
    "# Adjust the layout to make space between subplots\n",
    "plt.suptitle(\"Relative Accuracy vs FID for conventional transformations\", fontsize = 28)\n",
    "fig.text(0.5, 0.02, 'FID', ha='center', va='center', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ImageGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ??GANs??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy vs alpha\n",
    "### Conventional vs ImageGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conventional vs GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ??All together with real-only??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
